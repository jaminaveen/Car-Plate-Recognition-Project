{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import boto3\n",
    "import configparser\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.activations import relu, sigmoid, softmax\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8874150701308247250\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#ignore warnings in the output\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# Check all available devices if GPU is available\n",
    "print(device_lib.list_local_devices())\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWS_access_credentials', 'Plate_Dataset_Bucket']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../conf/config.cfg')\n",
    "config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = config['AWS_access_credentials']['aws_access_key_id']\n",
    "aws_secret_access_key = config['AWS_access_credentials']['aws_secret_access_key']\n",
    "bucket_name = config['Plate_Dataset_Bucket']['bucket_name']\n",
    "object_name = config['Plate_Dataset_Bucket']['object_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data-pipeline-license-plate'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3',\n",
    "                    aws_access_key_id = aws_access_key_id,\n",
    "                    aws_secret_access_key = aws_secret_access_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://info7374.s3.amazonaws.com/Pa140025.jpg']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_objecturls(bucket, client=s3_client):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - bucket: s3 bucket with target contents\n",
    "    - client: initialized s3 client object\n",
    "    \"\"\"\n",
    "\n",
    "    next_token = ''\n",
    "    urls = []\n",
    "    base_kwargs = {\n",
    "        'Bucket':bucket,\n",
    "        \n",
    "    }\n",
    "    while next_token is not None:\n",
    "        kwargs = base_kwargs.copy()\n",
    "        if next_token != '':\n",
    "            kwargs.update({'ContinuationToken': next_token})\n",
    "        results = client.list_objects_v2(**kwargs)\n",
    "        contents = results.get('Contents')\n",
    "        #print(contents)\n",
    "        for i in contents:\n",
    "            k = i.get('Key')\n",
    "            url = \"https://%s.s3.amazonaws.com/%s/%s\" % (bucket,prefix, k)\n",
    "            urls.append(url)\n",
    "        next_token = results.get('NextContinuationToken')\n",
    "\n",
    "    return urls\n",
    "\n",
    "            #https://info7374.s3.amazonaws.com/Pa140025.jpg\n",
    "\n",
    "urls = get_objecturls('info7374', client=s3_client)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dir(prefix, local, bucket, client=s3_client):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    - prefix: pattern to match in s3\n",
    "    - local: local path to folder in which to place files\n",
    "    - bucket: s3 bucket with target contents\n",
    "    - client: initialized s3 client object\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    dirs = []\n",
    "    next_token = ''\n",
    "    base_kwargs = {\n",
    "        'Bucket':bucket,\n",
    "        'Prefix':prefix,\n",
    "    }\n",
    "    while next_token is not None:\n",
    "        kwargs = base_kwargs.copy()\n",
    "        if next_token != '':\n",
    "            kwargs.update({'ContinuationToken': next_token})\n",
    "        results = client.list_objects_v2(**kwargs)\n",
    "        contents = results.get('Contents')\n",
    "        for i in contents:\n",
    "            k = i.get('Key')\n",
    "            if k[-1] != '/':\n",
    "                keys.append(k)\n",
    "            else:\n",
    "                dirs.append(k)\n",
    "        next_token = results.get('NextContinuationToken')\n",
    "    for d in dirs:\n",
    "        dest_pathname = os.path.join(local, d)\n",
    "        if not os.path.exists(os.path.dirname(dest_pathname)):\n",
    "            os.makedirs(os.path.dirname(dest_pathname))\n",
    "    for k in keys:\n",
    "        dest_pathname = os.path.join(local, k)\n",
    "        if not os.path.exists(os.path.dirname(dest_pathname)):\n",
    "            os.makedirs(os.path.dirname(dest_pathname))\n",
    "        client.download_file(bucket, k, dest_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir('License-plate', '../data/crnn_train', bucket_name, client=s3_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_list:   'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "# total number of our output classes: len(char_list)\n",
    "char_list = string.ascii_letters+string.digits+' '\n",
    " \n",
    "def encode_to_labels(txt):\n",
    "    # encoding each output word into digits\n",
    "    dig_lst = []\n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(char_list.index(char))\n",
    "        except:\n",
    "            print(char)\n",
    "            dig_lst.append(char_list.index(' '))\n",
    "        \n",
    "    return dig_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/crnn_train'\n",
    "\n",
    "len(os.listdir(path+'/'+os.listdir(path)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.download_file(bucket_name, 'License-plate/006 RSZ_13861166cf2e47.png', 'FILE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "@\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "&\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "path = '..\\data\\crnn_train'\n",
    "\n",
    "# lists for training dataset\n",
    "training_img = []\n",
    "training_txt = []\n",
    "train_input_length = []\n",
    "train_label_length = []\n",
    "orig_txt = []\n",
    " \n",
    "#lists for validation dataset\n",
    "valid_img = []\n",
    "valid_txt = []\n",
    "valid_input_length = []\n",
    "valid_label_length = []\n",
    "valid_orig_txt = []\n",
    " \n",
    "max_label_len = 0\n",
    " \n",
    "i =1 \n",
    "flag = 0\n",
    " \n",
    "for root, dirnames, filenames in os.walk(path):\n",
    "    #print(filenames)\n",
    " \n",
    "    for f_name in fnmatch.filter(filenames, '*.png'):\n",
    "        #print(f_name)\n",
    "        # read input image and convert into gray scale image\n",
    "        #print(os.path.join(root, f_name))\n",
    "        img = cv2.cvtColor(cv2.imread(os.path.join(root, f_name)), cv2.COLOR_BGR2GRAY)   \n",
    " \n",
    "        # convert each image of shape (32, 128, 1)\n",
    "        w, h = img.shape\n",
    "        #print(w,h)\n",
    "        if h > 128 or w > 32:\n",
    "            img = cv2.resize(img, (128,32), interpolation = cv2.INTER_AREA)\n",
    "        if w < 32:\n",
    "            add_zeros = np.ones((32-w, h))*255\n",
    "            img = np.concatenate((img, add_zeros))\n",
    " \n",
    "        if h < 128:\n",
    "            add_zeros = np.ones((32, 128-h))*255\n",
    "            img = np.concatenate((img, add_zeros), axis=1)\n",
    "        img = np.expand_dims(img , axis = 2)\n",
    "        #print(img.shape)\n",
    "        \n",
    "        # Normalize each image\n",
    "        img = img/255.\n",
    "        \n",
    "        # get the text from the image\n",
    "        txt = f_name.split('_')[0]\n",
    "        #print(txt)\n",
    "        # compute maximum length of the text\n",
    "        if len(txt) > max_label_len:\n",
    "            max_label_len = len(txt)\n",
    "            \n",
    "           \n",
    "        # split the 150000 data into validation and training dataset as 10% and 90% respectively\n",
    "        if i%10 == 0:     \n",
    "            valid_orig_txt.append(txt)   \n",
    "            valid_label_length.append(len(txt))\n",
    "            valid_input_length.append(31)\n",
    "            valid_img.append(img)\n",
    "            valid_txt.append(encode_to_labels(txt))\n",
    "        else:\n",
    "            orig_txt.append(txt)   \n",
    "            train_label_length.append(len(txt))\n",
    "            train_input_length.append(31)\n",
    "            training_img.append(img)\n",
    "            training_txt.append(encode_to_labels(txt)) \n",
    "        \n",
    "        # break the loop if total data is 150000\n",
    "        if i == len(os.listdir(path+'/'+os.listdir(path)[0])):\n",
    "            flag = 1\n",
    "            break\n",
    "        i+=1\n",
    "    if flag == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad each output label to maximum text length\n",
    " \n",
    "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
    "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input with shape of height=32 and width=128 \n",
    "inputs = Input(shape=(32,128,1))\n",
    " \n",
    "# convolution layer with kernel size (3,3)\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "# poolig layer with kernel size (2,2)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    " \n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    " \n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "# poolig layer with kernel size (2,1)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    " \n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "# Batch normalization layer\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    " \n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    " \n",
    "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
    " \n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    " \n",
    "# bidirectional LSTM layers with units=128\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    " \n",
    "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# model to be used at test time\n",
    "act_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 128, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 32, 256)        295168    \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 32, 256)        590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 32, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 32, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 32, 512)        2048      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 32, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 32, 512)        2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 32, 512)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 31, 512)        1049088   \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 31, 256)           656384    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 31, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 31, 64)            16448     \n",
      "=================================================================\n",
      "Total params: 6,619,968\n",
      "Trainable params: 6,617,920\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    " \n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "#model to be used at training time\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
    " \n",
    "filepath=\"best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img = np.array(training_img)\n",
    "train_input_length = np.array(train_input_length)\n",
    "train_label_length = np.array(train_label_length)\n",
    "\n",
    "valid_img = np.array(valid_img)\n",
    "valid_input_length = np.array(valid_input_length)\n",
    "valid_label_length = np.array(valid_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "900/900 [==============================] - 61s 68ms/step - loss: 37.9094 - val_loss: 27.0281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 27.02813, saving model to best_model.hdf5\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 50s 56ms/step - loss: 26.1086 - val_loss: 25.9563\n",
      "\n",
      "Epoch 00002: val_loss improved from 27.02813 to 25.95627, saving model to best_model.hdf5\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 52s 57ms/step - loss: 25.4450 - val_loss: 25.5736\n",
      "\n",
      "Epoch 00003: val_loss improved from 25.95627 to 25.57362, saving model to best_model.hdf5\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 53s 59ms/step - loss: 25.0490 - val_loss: 25.2051\n",
      "\n",
      "Epoch 00004: val_loss improved from 25.57362 to 25.20510, saving model to best_model.hdf5\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 52s 58ms/step - loss: 24.6849 - val_loss: 24.8294\n",
      "\n",
      "Epoch 00005: val_loss improved from 25.20510 to 24.82936, saving model to best_model.hdf5\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 54s 60ms/step - loss: 24.4974 - val_loss: 24.7662\n",
      "\n",
      "Epoch 00006: val_loss improved from 24.82936 to 24.76623, saving model to best_model.hdf5\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 55s 61ms/step - loss: 24.3488 - val_loss: 24.6976\n",
      "\n",
      "Epoch 00007: val_loss improved from 24.76623 to 24.69758, saving model to best_model.hdf5\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 55s 61ms/step - loss: 24.2239 - val_loss: 24.6044\n",
      "\n",
      "Epoch 00008: val_loss improved from 24.69758 to 24.60438, saving model to best_model.hdf5\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 54s 60ms/step - loss: 24.0524 - val_loss: 24.4262\n",
      "\n",
      "Epoch 00009: val_loss improved from 24.60438 to 24.42622, saving model to best_model.hdf5\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 53s 59ms/step - loss: 24.0103 - val_loss: 24.2653\n",
      "\n",
      "Epoch 00010: val_loss improved from 24.42622 to 24.26525, saving model to best_model.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1baf26aeda0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text =   110-CGV\n",
      "predicted text = \n",
      "\n",
      "original_text =   129-YBS\n",
      "predicted text = \n",
      "\n",
      "original_text =   15 904\n",
      "predicted text = \n",
      "\n",
      "original_text =   177309\n",
      "predicted text = \n",
      "\n",
      "original_text =   1B-691\n",
      "predicted text = \n",
      "\n",
      "original_text =   1D-432\n",
      "predicted text = \n",
      "\n",
      "original_text =   1F-605\n",
      "predicted text = \n",
      "\n",
      "original_text =   1H-232\n",
      "predicted text = \n",
      "\n",
      "original_text =   202 382\n",
      "predicted text = \n",
      "\n",
      "original_text =   252 8VN\n",
      "predicted text = \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the saved best model weights\n",
    "act_model.load_weights('best_model.hdf5')\n",
    " \n",
    "# predict outputs on validation images\n",
    "prediction = act_model.predict(valid_img[:10])\n",
    " \n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    " \n",
    "# see the results\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"original_text =  \", valid_orig_txt[i])\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(char_list[int(p)], end = '')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
